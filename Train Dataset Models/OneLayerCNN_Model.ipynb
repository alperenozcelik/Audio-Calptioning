{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Audio Images Model Test.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZSLEo5hDUc1q"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import librosa"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive') "
      ],
      "metadata": {
        "id": "UeRntqVrElEB",
        "outputId": "0791a143-d587-43cf-8f6e-3939c8d09c64",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataset(folder_path): \n",
        "  #This function creates images and species array from the image folder path.\n",
        "  images = []\n",
        "  names = []\n",
        "  max_length = 0\n",
        "  for file in os.listdir(folder_path):\n",
        "    image_path = os.path.join(folder_path, file)\n",
        "    #Resizing images and converting images to grayscale.\n",
        "    size = Image.open(image_path).size\n",
        "    image = np.array(Image.open(image_path).resize((int(size[0]/2),int(size[1]/2))))\n",
        "    image = image.astype('float32')\n",
        "    image = np.delete(image, [3], axis=2)\n",
        "    #Normalization\n",
        "    image /= 255.0\n",
        "    images.append(image)\n",
        "    names.append(file[:-4])\n",
        "    if image.shape[1]>max_length:\n",
        "      max_length = image.shape[1]\n",
        "\n",
        "  for i in range(len(images)):\n",
        "    images[i] = librosa.util.fix_length(images[i], max_length, axis=1)\n",
        "\n",
        "  images = np.array(images)\n",
        "\n",
        "  df = pd.read_csv('/content/drive/MyDrive/Deneme/clotho_metadata_development.csv')\n",
        "\n",
        "  keywords = []\n",
        "  for i in names:\n",
        "    keywords.append(df.keywords[df.file_name == i].to_list()[0].lower().split(';'))\n",
        "\n",
        "  return names,images,keywords"
      ],
      "metadata": {
        "id": "9G5r3tZAUtrH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "names, images, keywords = create_dataset(\"/content/drive/MyDrive/Train Images\")"
      ],
      "metadata": {
        "id": "P_b3nEq-U22w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_words = []\n",
        "for i in keywords:\n",
        "  for j in i:\n",
        "    if len(j)>2:\n",
        "      all_words.append(j)\n",
        "\n",
        "len(all_words)"
      ],
      "metadata": {
        "id": "cV4OnpTdEV0L",
        "outputId": "f9bfb5b1-c831-4050-9a78-b33c1009dd56",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21309"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "frequency_list = Counter(all_words).most_common(300)"
      ],
      "metadata": {
        "id": "kwGoLU1SIEUG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keywords_updated = []\n",
        "for j in range(len(keywords)):\n",
        "  keyword_list = []\n",
        "  for i in frequency_list:\n",
        "    if i[0] in keywords[j]:\n",
        "      keyword_list.append(i[0])\n",
        "  keywords_updated.append(keyword_list)"
      ],
      "metadata": {
        "id": "ZtL-YKsHGXrR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "mlb = MultiLabelBinarizer()\n",
        "multihot = mlb.fit_transform(keywords_updated)\n",
        "class_labels = list(mlb.classes_)"
      ],
      "metadata": {
        "id": "n_iGNl4KLw8B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, multihot, test_size=0.20, random_state=33)\n",
        "print(X_train.shape,X_test.shape)"
      ],
      "metadata": {
        "id": "KPyPRTikM92_",
        "outputId": "96858af9-c93e-4e5b-8588-82b872677dbf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2314, 64, 646, 3) (579, 64, 646, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers, models, optimizers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "def define_model():\n",
        "\n",
        "    input_shape=(64,646,3)\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape= input_shape))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(32, activation='relu', kernel_initializer='he_uniform'))  #Adding the Hidden layer\n",
        "    model.add(Dense(300, activation='softmax')) #Adding the Output Layer\n",
        "\n",
        "    \n",
        "    # compile model\n",
        "    opt = SGD(learning_rate = 0.0001, momentum=0.9)\n",
        "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "zxOR-c_BnrEC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = define_model()"
      ],
      "metadata": {
        "id": "0hBWc6sBnsMn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_train, epochs=10, validation_data= (X_test, y_test))"
      ],
      "metadata": {
        "id": "bxTP7J9env4Q",
        "outputId": "2e3a04c8-92c7-4bd2-a899-8077d2c3ddaf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "73/73 [==============================] - 61s 827ms/step - loss: 109.9500 - accuracy: 0.0428 - val_loss: 1058.3391 - val_accuracy: 0.0190\n",
            "Epoch 2/10\n",
            "73/73 [==============================] - 58s 797ms/step - loss: 237413760.0000 - accuracy: 0.0320 - val_loss: 53.9832 - val_accuracy: 0.0743\n",
            "Epoch 3/10\n",
            "73/73 [==============================] - 57s 786ms/step - loss: 3469.8748 - accuracy: 0.0415 - val_loss: 61656.1328 - val_accuracy: 0.0190\n",
            "Epoch 4/10\n",
            "73/73 [==============================] - 57s 777ms/step - loss: 2821117952.0000 - accuracy: 0.0160 - val_loss: 23.5143 - val_accuracy: 0.0052\n",
            "Epoch 5/10\n",
            "73/73 [==============================] - 57s 778ms/step - loss: 71.1672 - accuracy: 0.0039 - val_loss: 23.4016 - val_accuracy: 0.0035\n",
            "Epoch 6/10\n",
            "73/73 [==============================] - 57s 775ms/step - loss: 24.4315 - accuracy: 0.0052 - val_loss: 23.5192 - val_accuracy: 0.0639\n",
            "Epoch 7/10\n",
            "73/73 [==============================] - 57s 775ms/step - loss: 26.2187 - accuracy: 0.0601 - val_loss: 27.5290 - val_accuracy: 0.0743\n",
            "Epoch 8/10\n",
            "73/73 [==============================] - 57s 775ms/step - loss: 40.8009 - accuracy: 0.0592 - val_loss: 81.5999 - val_accuracy: 0.0743\n",
            "Epoch 9/10\n",
            "73/73 [==============================] - 57s 776ms/step - loss: 244934256.0000 - accuracy: 0.0367 - val_loss: 43.0241 - val_accuracy: 0.0052\n",
            "Epoch 10/10\n",
            "73/73 [==============================] - 56s 774ms/step - loss: 33.5636 - accuracy: 0.0056 - val_loss: 31.6964 - val_accuracy: 0.0052\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "43da6R29TiCr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}