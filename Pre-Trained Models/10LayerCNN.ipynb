{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "10LayerCNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iAckpuwKaJAL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import sys\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import librosa\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataset(folder_path): \n",
        "  images = []\n",
        "  names = []\n",
        " \n",
        "  for file in os.listdir(folder_path):\n",
        "\n",
        "    image_path = os.path.join(folder_path, file)\n",
        "\n",
        "    size = Image.open(image_path).size\n",
        "    image = np.array(Image.open(image_path).resize((int(size[0]/4),int(size[1]/2))))\n",
        "    image = image.astype('float32')\n",
        "    image = np.delete(image, [3], axis=2)\n",
        "\n",
        "    image /= 255.0\n",
        "    if file[:-4] != 'axqtExFY5-s (1)':\n",
        "      images.append(image)\n",
        "      names.append(file[:-4])\n",
        "\n",
        "  max_len = 0\n",
        "  for i in range(len(images)):\n",
        "    length = images[i].shape[1]\n",
        "    if length>max_len:\n",
        "      max_len=length\n",
        "\n",
        "  for i in range(len(images)):\n",
        "    images[i] = librosa.util.fix_length(images[i], int(max_len), axis=1)\n",
        "\n",
        "  images = np.array(images)\n",
        "\n",
        "  df = pd.read_csv('/content/drive/MyDrive/YouTubeID_and_Keywords.csv')\n",
        "\n",
        "  keywords = []\n",
        "  for i in names:\n",
        "    if i in df.YTID.to_list():\n",
        "      keys = df.Keywords[df.YTID == i].to_list()\n",
        "      keywords.append(keys[0].split(';'))\n",
        "    else:\n",
        "      print(i)\n",
        "\n",
        "  return names,images,keywords"
      ],
      "metadata": {
        "id": "pWl-0HwjaaGH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "names, images, keywords = create_dataset('/content/drive/MyDrive/Pre-Training Images')"
      ],
      "metadata": {
        "id": "g2x_zQQMaaCr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_words = []\n",
        "for i in keywords:\n",
        "  for j in i:\n",
        "    if len(j)>2:\n",
        "      all_words.append(j)\n",
        "      \n",
        "from collections import Counter\n",
        "\n",
        "frequency_list = Counter(all_words).most_common(300)\n",
        "\n",
        "keywords_updated = []\n",
        "for j in range(len(keywords)):\n",
        "  keyword_list = []\n",
        "  for i in frequency_list:\n",
        "    if i[0] in keywords[j]:\n",
        "      keyword_list.append(i[0])\n",
        "  keywords_updated.append(keyword_list)"
      ],
      "metadata": {
        "id": "aS7h926LVgID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "mlb = MultiLabelBinarizer()\n",
        "multihot = mlb.fit_transform(keywords_updated)\n",
        "class_labels = list(mlb.classes_)\n",
        "print(len(class_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VlF-5RKraaAd",
        "outputId": "6973b878-4c03-4837-e1ab-702f590bed11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, multihot, test_size=0.20, random_state=33)\n",
        "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMqBSqpIaZ-e",
        "outputId": "ef7dd38e-004b-4cf9-d7f1-7bb6386fa3c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(15100, 64, 107, 3) (3776, 64, 107, 3) (15100, 300) (3776, 300)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import shuffle\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Flatten\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from keras.layers.pooling import AveragePooling2D\n",
        "from keras.layers.normalization.batch_normalization import BatchNormalization\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "X8ZlJYzMaZ8f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create CNN model\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Input(shape=(64, 107, 3)))\n",
        "model.add(tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(tf.keras.layers.Conv2D(128, 3, padding='same', activation='relu'))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(tf.keras.layers.Conv2D(256, 3, padding='same', activation='relu'))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(tf.keras.layers.Conv2D(512, 3, padding='same', activation='relu'))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(1024, activation='relu'))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "model.add(tf.keras.layers.Dense(len(class_labels), activation='softmax'))"
      ],
      "metadata": {
        "id": "Y35IxdgeaZ0c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile model\n",
        "model.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    optimizer=SGD(learning_rate=0.0001, momentum=0.6),\n",
        "    metrics=['accuracy'],\n",
        ")"
      ],
      "metadata": {
        "id": "EO4lKWYSaZyF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_train, epochs=15, validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XtZlwjyWaZp_",
        "outputId": "d0000e33-006b-4429-8a47-e1b7f562834f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "472/472 [==============================] - 896s 2s/step - loss: 10.5358 - accuracy: 0.1158 - val_loss: 15.2190 - val_accuracy: 0.0040\n",
            "Epoch 2/15\n",
            "472/472 [==============================] - 904s 2s/step - loss: 9.5182 - accuracy: 0.1755 - val_loss: 9.2260 - val_accuracy: 0.1772\n",
            "Epoch 3/15\n",
            "472/472 [==============================] - 911s 2s/step - loss: 9.0464 - accuracy: 0.1902 - val_loss: 9.1352 - val_accuracy: 0.1917\n",
            "Epoch 4/15\n",
            "472/472 [==============================] - 998s 2s/step - loss: 8.7068 - accuracy: 0.2028 - val_loss: 8.7243 - val_accuracy: 0.2037\n",
            "Epoch 5/15\n",
            "472/472 [==============================] - 961s 2s/step - loss: 8.4625 - accuracy: 0.2077 - val_loss: 8.9073 - val_accuracy: 0.2018\n",
            "Epoch 6/15\n",
            "472/472 [==============================] - 889s 2s/step - loss: 8.3000 - accuracy: 0.2167 - val_loss: 8.5840 - val_accuracy: 0.2209\n",
            "Epoch 7/15\n",
            "472/472 [==============================] - 908s 2s/step - loss: 8.1625 - accuracy: 0.2185 - val_loss: 8.7442 - val_accuracy: 0.1986\n",
            "Epoch 8/15\n",
            "472/472 [==============================] - 858s 2s/step - loss: 8.0457 - accuracy: 0.2218 - val_loss: 9.9027 - val_accuracy: 0.1830\n",
            "Epoch 9/15\n",
            "472/472 [==============================] - 839s 2s/step - loss: 7.9337 - accuracy: 0.2230 - val_loss: 8.8741 - val_accuracy: 0.2172\n",
            "Epoch 10/15\n",
            "472/472 [==============================] - 876s 2s/step - loss: 7.8852 - accuracy: 0.2273 - val_loss: 8.4419 - val_accuracy: 0.2225\n",
            "Epoch 11/15\n",
            "472/472 [==============================] - 879s 2s/step - loss: 7.7872 - accuracy: 0.2296 - val_loss: 8.6003 - val_accuracy: 0.2103\n",
            "Epoch 12/15\n",
            "472/472 [==============================] - 850s 2s/step - loss: 7.7068 - accuracy: 0.2334 - val_loss: 9.3367 - val_accuracy: 0.2021\n",
            "Epoch 13/15\n",
            "472/472 [==============================] - 825s 2s/step - loss: 7.6294 - accuracy: 0.2377 - val_loss: 11.5011 - val_accuracy: 0.1618\n",
            "Epoch 14/15\n",
            "472/472 [==============================] - 879s 2s/step - loss: 7.5855 - accuracy: 0.2378 - val_loss: 8.5118 - val_accuracy: 0.2148\n",
            "Epoch 15/15\n",
            "472/472 [==============================] - 1025s 2s/step - loss: 7.5171 - accuracy: 0.2434 - val_loss: 9.9574 - val_accuracy: 0.2066\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "BeYTx-VYbGO7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}